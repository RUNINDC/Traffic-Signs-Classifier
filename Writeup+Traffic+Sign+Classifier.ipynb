{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Set Summary & Exploration##\n",
    "\n",
    "####1. Provide a basic summary of the data set and identify where in your code the summary was done. In the code, the analysis should be done using python, numpy and/or pandas methods rather than hardcoding results manually.\n",
    "\n",
    "Number of training examples = 34799\n",
    "Number of testing examples = 12630\n",
    "Image data shape = (32, 32, 3)\n",
    "Number of classes = 43\n",
    "\n",
    "X_train shape: (83245, 32, 32, 1)\n",
    "y_train shape: (83245,)\n",
    "X_test shape: (12630, 32, 32, 3)\n",
    "y_test shape: (12630,)\n",
    "\n",
    "**Question 1\n",
    "Describe the techniques used to preprocess the data.**\n",
    "\n",
    "For Data Reduction, I converted the images from RGB to grayscale - that way we don't have to preprocess the image with all three color channels seperately. \n",
    "\n",
    "Also I one-hot encoded the labels to make computing the cross entropy for the loss function possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/Real-world-images/Unknown.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 2\n",
    "Describe how you set up the training, validation and testing data for your model.**\n",
    "\n",
    "I built the validation set choosing random data, then applied the following methods: skew, perspective transforms and rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3\n",
    "What does your final architecture look like?**\n",
    "\n",
    "mu = 0 sigma = 0.1 Number of convolutional layers - 3 Number of fully connected layers - 2 \n",
    "\n",
    "**Layer 1:**\n",
    "Convolution of 5x5 kernel, 1 stride, 24 feature maps.  Activation: ReLU Pooling 1: 2x2 kernel and 2 stride.\n",
    "\n",
    "**Layer 2:**\n",
    "Convolution of 3x3 kernel, 1 stride and 32 feature maps Activation: ReLU Pooling 2: 2X2 kernel and 2 stride\n",
    "\n",
    "**Layer 3:** \n",
    "Fully connected layer with 512 units. ReLU activation\n",
    "\n",
    "**Layer 4:** Fully connnected with 256 units Activation: ReLU  \n",
    "Output Layer: Fully connected with 43 units for logits output. Activation: Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4. How did you train your model?**\n",
    "\n",
    "Adam optimizer with 0.001 Batch size. 128 Epochs and 15 Hyperparameters. Mean = 0; Standard Deviation of 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 What approach did you take in coming with a solution to this problem?**\n",
    "\n",
    "I used the Adam Optimizer because it performed well being adaptive.  With lower epochs, was able to obtain high accuracy. Used dropout of 0.5 for training and 1.0 for validation to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 7**\n",
    "Is your model able to perform equally well on captured pictures when compared to testing on the dataset? The simplest way to do this check the accuracy of the predictions. For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate.\n",
    "\n",
    "In the test set, the accuracy was 95%, but in the captured images, the accuracy was only 20% (1 out of 5)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
